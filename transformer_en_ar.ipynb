{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ptp-MXHZ7Stg",
        "outputId": "857427b0-e346-4c3e-a177-9066a0daa448"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIpmkUKVRXct",
        "outputId": "1920081f-3cd8-4f08-f858-201ab1ffeaad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'AMT_LLMs'...\n",
            "remote: Enumerating objects: 20, done.\u001b[K\n",
            "remote: Counting objects: 100% (20/20), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "Receiving objects: 100% (20/20), 44.45 KiB | 3.17 MiB/s, done.\n",
            "Resolving deltas: 100% (3/3), done.\n",
            "remote: Total 20 (delta 3), reused 0 (delta 0), pack-reused 0\u001b[K\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/zouidine/AMT_LLMs.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install mosestokenizer"
      ],
      "metadata": {
        "id": "VDYRLL3vGpG1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4fcd8c2-9cc0-43d4-fa08-34d0c1379d0d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mosestokenizer\n",
            "  Downloading mosestokenizer-1.2.1.tar.gz (37 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting docopt (from mosestokenizer)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting openfile (from mosestokenizer)\n",
            "  Downloading openfile-0.0.7-py3-none-any.whl (2.4 kB)\n",
            "Collecting uctools (from mosestokenizer)\n",
            "  Downloading uctools-1.3.0.tar.gz (4.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting toolwrapper (from mosestokenizer)\n",
            "  Downloading toolwrapper-2.1.0.tar.gz (3.2 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: mosestokenizer, docopt, toolwrapper, uctools\n",
            "  Building wheel for mosestokenizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mosestokenizer: filename=mosestokenizer-1.2.1-py3-none-any.whl size=49171 sha256=544c6016e32469b65aadc540a42fdc80dc9aa7dd62841eae1ca78754915330b5\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/d8/15/4c5ebbe883513f003cb055a0369c77c9df857023a706f39e70\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=6bb13ba9da4c2bb157cd1c935a23b1e67d61cbdad7bbe9e284fb0bb4e913e603\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "  Building wheel for toolwrapper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for toolwrapper: filename=toolwrapper-2.1.0-py3-none-any.whl size=3336 sha256=e292d45e8e288c418b8c184c2d2c4e9299fcd986d3381626beb52364dc4cf644\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/af/b1/99b57a06dda78fdcee86d2e22c64743f3b8df8f31cfc04baf7\n",
            "  Building wheel for uctools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for uctools: filename=uctools-1.3.0-py3-none-any.whl size=6146 sha256=47641222760d297a7474999eda445e485ca458ba9bc828de138d1473622b756f\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/ee/10/33257b0801ac6a912c841939032c16da1eb3db377afe1443e5\n",
            "Successfully built mosestokenizer docopt toolwrapper uctools\n",
            "Installing collected packages: toolwrapper, openfile, docopt, uctools, mosestokenizer\n",
            "Successfully installed docopt-0.6.2 mosestokenizer-1.2.1 openfile-0.0.7 toolwrapper-2.1.0 uctools-1.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip  install -U farasapy"
      ],
      "metadata": {
        "id": "XCwqaoQtGojE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3481dbd5-d0de-40ae-acf2-482c52fdd900"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting farasapy\n",
            "  Downloading farasapy-0.0.14-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from farasapy) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from farasapy) (4.66.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->farasapy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->farasapy) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->farasapy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->farasapy) (2024.7.4)\n",
            "Installing collected packages: farasapy\n",
            "Successfully installed farasapy-0.0.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bert-score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-eo93sOUjGW",
        "outputId": "5943d2a8-bea4-45fb-91eb-18b0be1506ea"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bert-score\n",
            "  Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/61.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from bert-score) (2.3.0+cu121)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from bert-score) (2.0.3)\n",
            "Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from bert-score) (4.41.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bert-score) (1.25.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bert-score) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.10/dist-packages (from bert-score) (4.66.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from bert-score) (3.7.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from bert-score) (24.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert-score) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert-score) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert-score) (2024.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.0.0->bert-score)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.0.0->bert-score)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.0.0->bert-score)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.0.0->bert-score)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.0.0->bert-score)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.0.0->bert-score)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.0.0->bert-score)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.0.0->bert-score)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.0.0->bert-score)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.0.0->bert-score)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.0.0->bert-score)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.0.0->bert-score)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (0.23.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (2024.5.15)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (0.4.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (3.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score) (2024.7.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert-score) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0.0->bert-score) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.0.0->bert-score) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, bert-score\n",
            "Successfully installed bert-score-0.3.13 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2EBwTN914p7"
      },
      "source": [
        "# Prepeocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "59ixXYQgyC0K"
      },
      "outputs": [],
      "source": [
        "from farasa.segmenter import FarasaSegmenter\n",
        "from mosestokenizer import *\n",
        "import torch\n",
        "import re\n",
        "\n",
        "class Preprocessing():\n",
        "\n",
        "    def __init__(self, lang):\n",
        "        self.lang = lang\n",
        "        self.word2index = {\"<PAD>\":0, \"<SOS>\":1, \"<EOS>\":2, \"<UNK>\":3}\n",
        "        self.index2word = {0:\"<PAD>\", 1:\"<SOS>\", 2:\"<EOS>\", 3:\"<UNK>\"}\n",
        "        self.word_count = {}\n",
        "        self.n_words = 4\n",
        "\n",
        "    # English preprocessing\n",
        "    def en_clean(self, sentence):\n",
        "        return re.sub(r\"[^a-zA-Z0-9.?!' ]+\", \"\", sentence)\n",
        "\n",
        "    def lowercase(self, sentence):\n",
        "      return sentence.lower()\n",
        "\n",
        "    # Arabic preprocessing\n",
        "    def ar_clean(self, sentence):\n",
        "        #remove punctuations\n",
        "        arabic_punctuations = '''`÷×؛<>_()*&^%][،/:\"'{}~¦+|”…“–ـ\\#=-,٬@—‘♫;٪อรอย$♪'''\n",
        "        translator = str.maketrans('', '', arabic_punctuations)\n",
        "        sentence = sentence.translate(translator)\n",
        "        #hindi numbers to arabic numbers\n",
        "        hindi_nums = \"٠١٢٣٤٥٦٧٨٩\"\n",
        "        arabic_nums = \"0123456789\"\n",
        "        hindi_to_arabic_map = str.maketrans(hindi_nums, arabic_nums)\n",
        "        sentence = sentence.translate(hindi_to_arabic_map)\n",
        "        #remove elongations\n",
        "        sentence = re.sub(r'(.)\\1+', r'\\1', sentence)\n",
        "        return sentence\n",
        "\n",
        "    def normalize(self, sentence):\n",
        "        #remove diacritics\n",
        "        arabic_diacritics = re.compile(\"\"\"\n",
        "                                ّ    | # Tashdid\n",
        "                                َ    | # Fatha\n",
        "                                ً    | # Tanwin Fath\n",
        "                                ُ    | # Damma\n",
        "                                ٌ    | # Tanwin Damm\n",
        "                                ِ    | # Kasra\n",
        "                                ٍ    | # Tanwin Kasr\n",
        "                                ْ    | # Sukun\n",
        "                                ـ     # Tatwil/Kashida\n",
        "                            \"\"\", re.VERBOSE)\n",
        "        sentence = re.sub(arabic_diacritics, '', sentence)\n",
        "        sentence = re.sub(\"[إأآا]\", \"ا\", sentence)\n",
        "        sentence = re.sub(\"ى\", \"ي\", sentence)\n",
        "        sentence = re.sub(\"ة\", \"ه\", sentence)\n",
        "        return sentence\n",
        "\n",
        "    def clean(self, l_sen):\n",
        "        if self.lang == 'ar':\n",
        "            return [self.ar_clean(sen) for sen in l_sen]\n",
        "        else: return [self.en_clean(sen) for sen in l_sen]\n",
        "\n",
        "    def tokenize(self, l_sen):\n",
        "        l = l_sen\n",
        "        if self.lang == 'ar':\n",
        "            tokenize = MosesTokenizer(lang=\"ar\")\n",
        "            farasa_segmenter = FarasaSegmenter(interactive=True)\n",
        "            l = [farasa_segmenter.segment(sen) for sen in l]\n",
        "            l = [self.normalize(sen) for sen in l]\n",
        "            return [[\"<SOS>\"] + tokenize(sen) + [\"<EOS>\"] for sen in l]\n",
        "        else:\n",
        "            tokenize = MosesTokenizer('en', no_escape=True)\n",
        "            l = [self.lowercase(sen) for sen in l]\n",
        "            tkns = [[\"<SOS>\"] + tokenize(sen) + [\"<EOS>\"] for sen in l]\n",
        "            return [[tkn for tkn in sen if tkn != \"'\"] for sen in tkns]\n",
        "\n",
        "    def creat_vocabulary(self, sentences):\n",
        "        for sentence in sentences:\n",
        "            for word in sentence:\n",
        "                if word not in self.word_count:\n",
        "                    self.word_count[word] = 1\n",
        "                else: self.word_count[word] += 1\n",
        "                if word not in self.word2index and self.word_count[word]>=2:\n",
        "                    self.word2index[word] = self.n_words\n",
        "                    self.index2word[self.n_words] = word\n",
        "                    self.n_words += 1\n",
        "\n",
        "    def creat_tensors(self, l_sen_tkn):\n",
        "        max_len = max([len(sen) for sen in l_sen_tkn])\n",
        "        batch = len(l_sen_tkn)\n",
        "        tensor_data = torch.zeros(batch, max_len, dtype=torch.long)\n",
        "        tensor_mask = []\n",
        "        for i in range(batch):\n",
        "            ids = [self.word2index.get(w, self.word2index[\"<UNK>\"]) for w in l_sen_tkn[i]]\n",
        "            tensor_data[i, 0:len(ids)] = torch.tensor(ids, dtype=torch.long)\n",
        "            tensor_mask.append(len(ids))\n",
        "        return tensor_data, torch.tensor(tensor_mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMswNlIi3Vgf"
      },
      "source": [
        "#Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "x2h3h7DMr2OX"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pack_padded_sequence\n",
        "\n",
        "def get_positional_encoding(d_model, max_length=100):\n",
        "    positional_encoding = torch.zeros((max_length, d_model))\n",
        "    for i in range(max_length):\n",
        "        for j in range(d_model):\n",
        "            if j % 2 == 0:\n",
        "                positional_encoding[i, j] = math.sin(i/math.\n",
        "                                                     pow(10000, j/d_model))\n",
        "            else:\n",
        "                positional_encoding[i, j] = math.cos(i/math.\n",
        "                                                     pow(10000, (j - 1)/d_model))\n",
        "\n",
        "    ## (1, max_length, d_model)\n",
        "    positional_encoding = positional_encoding.unsqueeze(0)\n",
        "\n",
        "    return positional_encoding\n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    The Multi-Head Attention sublayer.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, d_model, n_heads, d_queries, d_values, dropout,\n",
        "                 in_decoder=False):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.n_heads = n_heads\n",
        "\n",
        "        self.d_queries = d_queries\n",
        "        self.d_values = d_values\n",
        "        self.d_keys = d_queries\n",
        "\n",
        "        self.in_decoder = in_decoder\n",
        "\n",
        "        self.cast_queries = nn.Linear(d_model, n_heads*d_queries)\n",
        "\n",
        "        self.cast_keys_values = nn.Linear(d_model, n_heads*(d_queries+d_values))\n",
        "\n",
        "        self.cast_output = nn.Linear(n_heads*d_values, d_model)\n",
        "\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "\n",
        "        self.layer_norm = nn.LayerNorm(d_model)\n",
        "\n",
        "        self.apply_dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, query_sequences, key_value_sequences,\n",
        "                key_value_sequence_lengths):\n",
        "        batch_size = query_sequences.size(0)\n",
        "        query_sequence_pad_length = query_sequences.size(1)\n",
        "        key_value_sequence_pad_length = key_value_sequences.size(1)\n",
        "\n",
        "        # Is this self-attention?\n",
        "        self_attention = torch.equal(key_value_sequences, query_sequences)\n",
        "\n",
        "        # Store input for adding later\n",
        "        input_to_add = query_sequences.clone()\n",
        "\n",
        "        # Apply layer normalization\n",
        "        ## (N, query_sequence_pad_length, d_model)\n",
        "        query_sequences = self.layer_norm(query_sequences)\n",
        "        if self_attention:\n",
        "            ## (N, key_value_sequence_pad_length, d_model)\n",
        "            key_value_sequences = self.layer_norm(key_value_sequences)\n",
        "\n",
        "        # Project input sequences to queries, keys, values\n",
        "        ## (N, query_sequence_pad_length, n_heads*d_queries)\n",
        "        queries = self.cast_queries(query_sequences)\n",
        "        ## (N, key_value_sequence_pad_length, n_heads*d_keys)\n",
        "        ## (N, key_value_sequence_pad_length, n_heads*d_values)\n",
        "        keys, values = self.cast_keys_values(key_value_sequences\n",
        "                                             ).split(split_size=self.n_heads*\n",
        "                                                     self.d_keys, dim=-1)\n",
        "\n",
        "        # Split the last dimension by the n_heads subspaces\n",
        "        ## (N, query_sequence_pad_length, n_heads, d_queries)\n",
        "        queries = queries.contiguous().view(batch_size, query_sequence_pad_length,\n",
        "                                            self.n_heads, self.d_queries)\n",
        "        ## (N, key_value_sequence_pad_length, n_heads, d_keys)\n",
        "        keys = keys.contiguous().view(batch_size, key_value_sequence_pad_length,\n",
        "                                      self.n_heads, self.d_keys)\n",
        "        ## (N, key_value_sequence_pad_length, n_heads, d_values)\n",
        "        values = values.contiguous().view(batch_size,\n",
        "                                          key_value_sequence_pad_length,\n",
        "                                          self.n_heads, self.d_values)\n",
        "\n",
        "        # Re-arrange axes such that the last two dimensions are the sequence\n",
        "        # lengths and the queries/keys/values. And then, for convenience,\n",
        "        # convert to 3D tensors by merging the batch and n_heads dimensions\n",
        "        # This is to prepare it for the batch matrix multiplication\n",
        "        ## (N * n_heads, query_sequence_pad_length, d_queries)\n",
        "        queries = queries.permute(0, 2, 1, 3\n",
        "                                  ).contiguous().view(-1,\n",
        "                                                      query_sequence_pad_length,\n",
        "                                                      self.d_queries)\n",
        "        ## (N * n_heads, key_value_sequence_pad_length, d_keys)\n",
        "        keys = keys.permute(0, 2, 1, 3\n",
        "                            ).contiguous().view(-1,\n",
        "                                                key_value_sequence_pad_length,\n",
        "                                                self.d_keys)\n",
        "        ## (N * n_heads, key_value_sequence_pad_length, d_values)\n",
        "        values = values.permute(0, 2, 1, 3\n",
        "                                ).contiguous().view(-1,\n",
        "                                                    key_value_sequence_pad_length,\n",
        "                                                    self.d_values)\n",
        "\n",
        "        # Perform multi-head attention\n",
        "\n",
        "        # Perform dot-products\n",
        "        ## (N * n_heads, query_sequence_pad_length, key_value_sequence_pad_length)\n",
        "        attention_weights = torch.bmm(queries, keys.permute(0, 2, 1))\n",
        "\n",
        "        # Scale dot-products\n",
        "        ## (N * n_heads, query_sequence_pad_length, key_value_sequence_pad_length)\n",
        "        attention_weights = (1. / math.sqrt(self.d_keys)) * attention_weights\n",
        "\n",
        "        # Before computing softmax weights, prevent queries from attending to certain keys\n",
        "\n",
        "        # MASK 1: keys that are pads\n",
        "        ## (N * n_heads, query_sequence_pad_length, key_value_sequence_pad_length)\n",
        "        not_pad_in_keys = torch.LongTensor(range(key_value_sequence_pad_length)\n",
        "        ).unsqueeze(0).unsqueeze(0).expand_as(attention_weights).to(device)\n",
        "        not_pad_in_keys = not_pad_in_keys < key_value_sequence_lengths.\\\n",
        "                            repeat_interleave(self.n_heads).unsqueeze(\n",
        "                                1).unsqueeze(2).expand_as(attention_weights)\n",
        "\n",
        "        attention_weights = attention_weights.masked_fill(~not_pad_in_keys,\n",
        "                                                          -float('inf'))\n",
        "\n",
        "        # MASK 2: if this is self-attention in the decoder,\n",
        "        # keys chronologically ahead of queries\n",
        "        if self.in_decoder and self_attention:\n",
        "            # Therefore, a position [n, i, j] is valid only if j <= i\n",
        "            # torch.tril(), i.e. lower triangle in a 2D matrix, sets j > i to 0\n",
        "            not_future_mask = torch.ones_like(attention_weights\n",
        "                                              ).tril().bool().to(device)\n",
        "\n",
        "            # Mask away by setting such weights to a large negative number,\n",
        "            # so that they evaluate to 0 under the softmax\n",
        "            attention_weights = attention_weights.masked_fill(~not_future_mask,\n",
        "                                                              -float('inf'))\n",
        "\n",
        "        # Compute softmax along the key dimension\n",
        "        attention_weights = self.softmax(attention_weights)\n",
        "\n",
        "        # Apply dropout\n",
        "        ## (N * n_heads, query_sequence_pad_length, key_value_sequence_pad_length)\n",
        "        attention_weights = self.apply_dropout(attention_weights)\n",
        "\n",
        "        # Calculate sequences as the weighted sums of values based on these softmax weights\n",
        "        ## (N * n_heads, query_sequence_pad_length, d_values)\n",
        "        sequences = torch.bmm(attention_weights, values)\n",
        "\n",
        "        # Unmerge batch and n_heads dimensions and restore original order of axes\n",
        "        ## (N, query_sequence_pad_length, n_heads, d_values)\n",
        "        sequences = sequences.contiguous().view(batch_size, self.n_heads,\n",
        "                                                query_sequence_pad_length,\n",
        "                                                self.d_values).permute(0, 2, 1, 3)\n",
        "\n",
        "        # Concatenate the n_heads subspaces (each with an output of size d_values)\n",
        "        ## (N, query_sequence_pad_length, n_heads * d_values)\n",
        "        sequences = sequences.contiguous().view(batch_size,\n",
        "                                                query_sequence_pad_length, -1)\n",
        "\n",
        "        # Transform the concatenated subspace-sequences into a single output of size d_model\n",
        "        ## (N, query_sequence_pad_length, d_model)\n",
        "        sequences = self.cast_output(sequences)\n",
        "\n",
        "        # Apply dropout and residual connection\n",
        "        sequences = self.apply_dropout(sequences) + input_to_add\n",
        "\n",
        "        return sequences\n",
        "\n",
        "\n",
        "class PositionWiseFCNetwork(nn.Module):\n",
        "    \"\"\"\n",
        "    The Position-Wise Feed Forward Network sublayer.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, d_model, d_inner, dropout):\n",
        "        super(PositionWiseFCNetwork, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.d_inner = d_inner\n",
        "\n",
        "        # Layer-norm layer\n",
        "        self.layer_norm = nn.LayerNorm(d_model)\n",
        "\n",
        "        # A linear layer to project from the input size to an intermediate size\n",
        "        self.fc1 = nn.Linear(d_model, d_inner)\n",
        "\n",
        "        # ReLU\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        # A linear layer to project from the intermediate size to the output size (same as the input size)\n",
        "        self.fc2 = nn.Linear(d_inner, d_model)\n",
        "\n",
        "        # Dropout layer\n",
        "        self.apply_dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, sequences):\n",
        "        # Store input for adding later\n",
        "        input_to_add = sequences.clone()  # (N, pad_length, d_model)\n",
        "\n",
        "        # Apply layer-norm\n",
        "        sequences = self.layer_norm(sequences)  # (N, pad_length, d_model)\n",
        "\n",
        "        # Transform position-wise\n",
        "        ## (N, pad_length, d_inner)\n",
        "        sequences = self.apply_dropout(self.relu(self.fc1(sequences)))\n",
        "        sequences = self.fc2(sequences)  # (N, pad_length, d_model)\n",
        "\n",
        "        # Apply dropout and residual connection\n",
        "        ## (N, pad_length, d_model)\n",
        "        sequences = self.apply_dropout(sequences) + input_to_add\n",
        "\n",
        "        return sequences\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    \"\"\"\n",
        "    The Encoder.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, vocab_size, positional_encoding, d_model, n_heads,\n",
        "                 d_queries, d_values, d_inner, n_layers, dropout):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.vocab_size = vocab_size\n",
        "        self.positional_encoding = positional_encoding\n",
        "        self.d_model = d_model\n",
        "        self.n_heads = n_heads\n",
        "        self.d_queries = d_queries\n",
        "        self.d_values = d_values\n",
        "        self.d_inner = d_inner\n",
        "        self.n_layers = n_layers\n",
        "        self.dropout = dropout\n",
        "\n",
        "        # An embedding layer\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
        "\n",
        "        # Set the positional encoding tensor to be un-update-able\n",
        "        self.positional_encoding.requires_grad = False\n",
        "\n",
        "        # Encoder layers\n",
        "        self.encoder_layers = nn.ModuleList([self.make_encoder_layer() for i\n",
        "                                             in range(n_layers)])\n",
        "\n",
        "        # Dropout layer\n",
        "        self.apply_dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # Layer-norm layer\n",
        "        self.layer_norm = nn.LayerNorm(d_model)\n",
        "\n",
        "    def make_encoder_layer(self):\n",
        "        # A ModuleList of sublayers\n",
        "        encoder_layer = nn.ModuleList([MultiHeadAttention(d_model=self.d_model,\n",
        "                                                          n_heads=self.n_heads,\n",
        "                                                          d_queries=self.d_queries,\n",
        "                                                          d_values=self.d_values,\n",
        "                                                          dropout=self.dropout,\n",
        "                                                          in_decoder=False),\n",
        "                                       PositionWiseFCNetwork(d_model=self.d_model,\n",
        "                                                             d_inner=self.d_inner,\n",
        "                                                             dropout=self.dropout)])\n",
        "\n",
        "        return encoder_layer\n",
        "\n",
        "    def forward(self, encoder_sequences, encoder_sequence_lengths):\n",
        "        # pad-length of this batch only, varies across batches\n",
        "        pad_length = encoder_sequences.size(1)\n",
        "\n",
        "        # Sum vocab embeddings and position embeddings\n",
        "        encoder_sequences = self.embedding(encoder_sequences) *\\\n",
        "                            math.sqrt(self.d_model) +\\\n",
        "                            self.positional_encoding[:, :pad_length, :].to(\n",
        "                                device)  # (N, pad_length, d_model)\n",
        "\n",
        "        # Dropout\n",
        "        encoder_sequences = self.apply_dropout(encoder_sequences)\n",
        "\n",
        "        # Encoder layers\n",
        "        for encoder_layer in self.encoder_layers:\n",
        "            # Sublayers\n",
        "            encoder_sequences = encoder_layer[0](encoder_sequences,\n",
        "                                                 encoder_sequences,\n",
        "                                                 encoder_sequence_lengths)\n",
        "            encoder_sequences = encoder_layer[1](encoder_sequences)\n",
        "\n",
        "        # Apply layer-norm\n",
        "        ## (N, pad_length, d_model)\n",
        "        encoder_sequences = self.layer_norm(encoder_sequences)\n",
        "\n",
        "        return encoder_sequences\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    \"\"\"\n",
        "    The Decoder.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, vocab_size, positional_encoding, d_model, n_heads,\n",
        "                 d_queries, d_values, d_inner, n_layers, dropout):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.vocab_size = vocab_size\n",
        "        self.positional_encoding = positional_encoding\n",
        "        self.d_model = d_model\n",
        "        self.n_heads = n_heads\n",
        "        self.d_queries = d_queries\n",
        "        self.d_values = d_values\n",
        "        self.d_inner = d_inner\n",
        "        self.n_layers = n_layers\n",
        "        self.dropout = dropout\n",
        "\n",
        "        # An embedding layer\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
        "\n",
        "        # Set the positional encoding tensor to be un-update-able\n",
        "        self.positional_encoding.requires_grad = False\n",
        "\n",
        "        # Decoder layers\n",
        "        self.decoder_layers = nn.ModuleList([self.make_decoder_layer() for i\n",
        "                                             in range(n_layers)])\n",
        "\n",
        "        # Dropout layer\n",
        "        self.apply_dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # Layer-norm layer\n",
        "        self.layer_norm = nn.LayerNorm(d_model)\n",
        "\n",
        "        # Output linear layer that will compute logits for the vocabulary\n",
        "        self.fc = nn.Linear(d_model, vocab_size)\n",
        "\n",
        "    def make_decoder_layer(self):\n",
        "        # A ModuleList of sublayers\n",
        "        decoder_layer = nn.ModuleList([MultiHeadAttention(d_model=self.d_model,\n",
        "                                                          n_heads=self.n_heads,\n",
        "                                                          d_queries=self.d_queries,\n",
        "                                                          d_values=self.d_values,\n",
        "                                                          dropout=self.dropout,\n",
        "                                                          in_decoder=True),\n",
        "                                       MultiHeadAttention(d_model=self.d_model,\n",
        "                                                          n_heads=self.n_heads,\n",
        "                                                          d_queries=self.d_queries,\n",
        "                                                          d_values=self.d_values,\n",
        "                                                          dropout=self.dropout,\n",
        "                                                          in_decoder=True),\n",
        "                                       PositionWiseFCNetwork(d_model=self.d_model,\n",
        "                                                             d_inner=self.d_inner,\n",
        "                                                             dropout=self.dropout)])\n",
        "\n",
        "        return decoder_layer\n",
        "\n",
        "    def forward(self, decoder_sequences, decoder_sequence_lengths,\n",
        "                encoder_sequences, encoder_sequence_lengths):\n",
        "        pad_length = decoder_sequences.size(1)\n",
        "\n",
        "        # Sum vocab embeddings and position embeddings\n",
        "        decoder_sequences = self.embedding(decoder_sequences) *\\\n",
        "                             math.sqrt(self.d_model) +\\\n",
        "                             self.positional_encoding[:, :pad_length, :].to(\n",
        "                                 device)  # (N, pad_length, d_model)\n",
        "\n",
        "        # Dropout\n",
        "        decoder_sequences = self.apply_dropout(decoder_sequences)\n",
        "\n",
        "        # Decoder layers\n",
        "        for decoder_layer in self.decoder_layers:\n",
        "            # Sublayers\n",
        "            decoder_sequences = decoder_layer[0](decoder_sequences,\n",
        "                                                 decoder_sequences,\n",
        "                                                 decoder_sequence_lengths)\n",
        "            decoder_sequences = decoder_layer[1](decoder_sequences,\n",
        "                                                 encoder_sequences,\n",
        "                                                 encoder_sequence_lengths)\n",
        "            decoder_sequences = decoder_layer[2](decoder_sequences)\n",
        "\n",
        "        # Apply layer-norm\n",
        "        decoder_sequences = self.layer_norm(decoder_sequences)\n",
        "\n",
        "        # Find logits over vocabulary\n",
        "        ## (N, pad_length, vocab_size)\n",
        "        decoder_sequences = self.fc(decoder_sequences)\n",
        "\n",
        "        return decoder_sequences\n",
        "\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    \"\"\"\n",
        "    The Transformer network.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_vocab_size, out_vocab_size, positional_encoding,\n",
        "                 d_model=256, n_heads=8, d_queries=64, d_values=64,\n",
        "                 d_inner=1024, n_layers=4, dropout=0.1):\n",
        "        super(Transformer, self).__init__()\n",
        "\n",
        "        self.in_vocab_size = in_vocab_size\n",
        "        self.out_vocab_size = out_vocab_size\n",
        "        self.positional_encoding = positional_encoding\n",
        "        self.d_model = d_model\n",
        "        self.n_heads = n_heads\n",
        "        self.d_queries = d_queries\n",
        "        self.d_values = d_values\n",
        "        self.d_inner = d_inner\n",
        "        self.n_layers = n_layers\n",
        "        self.dropout = dropout\n",
        "\n",
        "        # Encoder\n",
        "        self.encoder = Encoder(vocab_size=in_vocab_size,\n",
        "                               positional_encoding=positional_encoding,\n",
        "                               d_model=d_model,\n",
        "                               n_heads=n_heads,\n",
        "                               d_queries=d_queries,\n",
        "                               d_values=d_values,\n",
        "                               d_inner=d_inner,\n",
        "                               n_layers=n_layers,\n",
        "                               dropout=dropout)\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder = Decoder(vocab_size=out_vocab_size,\n",
        "                               positional_encoding=positional_encoding,\n",
        "                               d_model=d_model,\n",
        "                               n_heads=n_heads,\n",
        "                               d_queries=d_queries,\n",
        "                               d_values=d_values,\n",
        "                               d_inner=d_inner,\n",
        "                               n_layers=n_layers,\n",
        "                               dropout=dropout)\n",
        "\n",
        "        # Initialize weights\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        \"\"\"\n",
        "        Initialize weights in the transformer model.\n",
        "        \"\"\"\n",
        "        # Glorot uniform initialization with a gain of 1.\n",
        "        for p in self.parameters():\n",
        "            # Glorot initialization needs at least two dimensions on the tensor\n",
        "            if p.dim() > 1:\n",
        "                nn.init.xavier_uniform_(p, gain=1.)\n",
        "\n",
        "        # Share weights between the embedding layers and the logit layer\n",
        "        nn.init.normal_(self.encoder.embedding.weight, mean=0.,\n",
        "                        std=math.pow(self.d_model, -0.5))\n",
        "        nn.init.normal_(self.decoder.embedding.weight, mean=0.,\n",
        "                        std=math.pow(self.d_model, -0.5))\n",
        "        self.decoder.fc.weight = self.decoder.embedding.weight\n",
        "\n",
        "        print(\"Model initialized.\")\n",
        "\n",
        "    def forward(self, encoder_sequences, decoder_sequences,\n",
        "                encoder_sequence_lengths, decoder_sequence_lengths):\n",
        "        # Encoder\n",
        "        ## (N, encoder_sequence_pad_length, d_model)\n",
        "        encoder_sequences = self.encoder(encoder_sequences,\n",
        "                                         encoder_sequence_lengths)\n",
        "\n",
        "        # Decoder\n",
        "        ## (N, decoder_sequence_pad_length, vocab_size)\n",
        "        decoder_sequences = self.decoder(decoder_sequences,\n",
        "                                         decoder_sequence_lengths,\n",
        "                                         encoder_sequences,\n",
        "                                         encoder_sequence_lengths)\n",
        "\n",
        "        return decoder_sequences\n",
        "\n",
        "\n",
        "class LabelSmoothedCE(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Cross Entropy loss with label-smoothing as a form of regularization.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, eps=0.1):\n",
        "        super(LabelSmoothedCE, self).__init__()\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, inputs, targets, lengths):\n",
        "        # Remove pad-positions and flatten\n",
        "        inputs, _, _, _ = pack_padded_sequence(input=inputs,\n",
        "                                               lengths=lengths.cpu(),\n",
        "                                               batch_first=True,\n",
        "                                               enforce_sorted=False)\n",
        "        targets, _, _, _ = pack_padded_sequence(input=targets,\n",
        "                                                lengths=lengths.cpu(),\n",
        "                                                batch_first=True,\n",
        "                                                enforce_sorted=False)\n",
        "\n",
        "        # \"Smoothed\" one-hot vectors for the gold sequences\n",
        "        ## (sum(lengths), n_classes), one-hot\n",
        "        target_vector = torch.zeros_like(inputs).scatter(dim=1,\n",
        "                                                         index=targets.unsqueeze(1),\n",
        "                                                         value=1.).to(device)\n",
        "        target_vector = target_vector * (1. - self.eps) +\\\n",
        "                         self.eps / target_vector.size(1)\n",
        "\n",
        "        # Compute smoothed cross-entropy loss\n",
        "        ## (sum(lengths))\n",
        "        loss = (-1 * target_vector * F.log_softmax(inputs, dim=1)).sum(dim=1)\n",
        "\n",
        "        # Compute mean loss\n",
        "        loss = torch.mean(loss)\n",
        "\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2IybB0q3ZUd"
      },
      "source": [
        "#Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "hYcOgPd-QKjk"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import torch\n",
        "\n",
        "def train(model, train_loader, device, foldername=\"\"):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "    criterion = LabelSmoothedCE()\n",
        "    if foldername != \"\":\n",
        "        final_path = foldername + \"final_en_ar.pth\"\n",
        "\n",
        "    best_valid_loss = 1e10\n",
        "\n",
        "    for epoch_no in range(10):\n",
        "        model.train()\n",
        "        avg_loss = 0\n",
        "        with tqdm(train_loader) as it:\n",
        "            for batch_no, (src, src_mask, trg, trg_mask) in enumerate(it,\n",
        "                                                                      start=1):\n",
        "                src, src_mask = src.to(device), src_mask.to(device)\n",
        "                trg, trg_mask = trg.to(device), trg_mask.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                output = model(src, trg, src_mask, trg_mask)\n",
        "                loss = criterion(output, trg[:,1:], trg_mask-1)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                avg_loss += loss.item()\n",
        "\n",
        "                it.set_postfix(\n",
        "                    ordered_dict={\n",
        "                        \"avg_epoch_loss\": avg_loss / batch_no,\n",
        "                        \"epoch\": epoch_no,\n",
        "                    },\n",
        "                    refresh=True,\n",
        "                )\n",
        "    if foldername != \"\":\n",
        "        torch.save(model.state_dict(), final_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "b9P_fAiB1sKt"
      },
      "outputs": [],
      "source": [
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "\n",
        "def translate(model, tensor, mask, preprocess, max_len=None):\n",
        "    model.eval()\n",
        "    outputs = []\n",
        "    detokenize = MosesDetokenizer(trg_lang)\n",
        "\n",
        "    encoder_output = model.encoder(tensor, mask)\n",
        "\n",
        "    for i in range(tensor.shape[0]):\n",
        "\n",
        "        out = ['<SOS>']\n",
        "\n",
        "        # Our hypothesis to begin with is just <BOS>\n",
        "        hypotheses = torch.LongTensor([[preprocess.word2index['<SOS>']]]\n",
        "                                      ).to(device)  # (1, 1)\n",
        "        hypotheses_lengths = torch.LongTensor([hypotheses.size(1)]).to(device)\n",
        "\n",
        "        tkn = 0\n",
        "        while(tkn != 2):\n",
        "            output = model.decoder(hypotheses,\n",
        "                                   hypotheses_lengths,\n",
        "                                   encoder_output[i].unsqueeze(0),\n",
        "                                   mask[i].unsqueeze(0))\n",
        "\n",
        "            tkn = output[:,-1,:].argmax().item()\n",
        "            out.append(preprocess.index2word[tkn])\n",
        "\n",
        "            if (len(out)==max_len): break\n",
        "\n",
        "            hypotheses = torch.cat([hypotheses,\n",
        "                                    torch.LongTensor([[tkn]]).to(device)],\n",
        "                                   dim=1)\n",
        "            hypotheses_lengths += 1\n",
        "        outputs.append(detokenize(out[1:-1]))\n",
        "\n",
        "    return outputs\n",
        "\n",
        "def evaluate(model, ref, tensor, mask, preprocessor):\n",
        "\n",
        "    detokenize = MosesDetokenizer(trg_lang)\n",
        "    references = [[detokenize(sen[1:-1])] for sen in ref]\n",
        "    candidates = translate(model, tensor, mask, preprocessor, 100)\n",
        "\n",
        "    bleu = corpus_bleu(references, candidates)\n",
        "\n",
        "    print(\"BLEU Score:\\t\", round(100*bleu,2))\n",
        "    return candidates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_aaeF1r3daw"
      },
      "source": [
        "#Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "2ecENinNrcaB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bee089f-a88e-47b8-c9d6-730f62e616c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***** Loading Data ...\n",
            "\n",
            "***** Tokenization ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py:1100: InsecureRequestWarning: Unverified HTTPS request is being made to host 'farasa-api.qcri.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100%|██████████| 241M/241M [02:01<00:00, 1.99MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2024-07-14 22:02:07,625 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "[2024-07-14 22:03:55,189 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Data size\t 150477\n",
            "\n",
            "***** Creating Vocabulary ...\n",
            "\ten Vocabulary size:\t25449\n",
            "\tar Vocabulary size:\t20736\n",
            "\n",
            "***** Creating tensors ...\n",
            "\n",
            "***** Creating Data loaders ...\n",
            "\n",
            "***** Creating Model ...\n",
            "Model initialized.\n",
            "\n",
            "***** Training ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1176/1176 [08:55<00:00,  2.20it/s, avg_epoch_loss=4.14, epoch=0]\n",
            "100%|██████████| 1176/1176 [09:06<00:00,  2.15it/s, avg_epoch_loss=3.29, epoch=1]\n",
            "100%|██████████| 1176/1176 [09:01<00:00,  2.17it/s, avg_epoch_loss=2.98, epoch=2]\n",
            "100%|██████████| 1176/1176 [08:57<00:00,  2.19it/s, avg_epoch_loss=2.81, epoch=3]\n",
            "100%|██████████| 1176/1176 [08:58<00:00,  2.18it/s, avg_epoch_loss=2.7, epoch=4]\n",
            "100%|██████████| 1176/1176 [09:03<00:00,  2.17it/s, avg_epoch_loss=2.62, epoch=5]\n",
            "100%|██████████| 1176/1176 [07:27<00:00,  2.63it/s, avg_epoch_loss=2.56, epoch=6]\n",
            "100%|██████████| 1176/1176 [08:53<00:00,  2.20it/s, avg_epoch_loss=2.5, epoch=7]\n",
            "100%|██████████| 1176/1176 [09:02<00:00,  2.17it/s, avg_epoch_loss=2.46, epoch=8]\n",
            "100%|██████████| 1176/1176 [08:57<00:00,  2.19it/s, avg_epoch_loss=2.41, epoch=9]\n"
          ]
        }
      ],
      "source": [
        "src_lang = 'en'\n",
        "trg_lang = 'ar'\n",
        "src_preprocess = Preprocessing(src_lang)\n",
        "trg_preprocess = Preprocessing(trg_lang)\n",
        "foldername = \"/content/drive/MyDrive/Colab/11-AMT_LLMs/\"\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# To enhance reproducibility\n",
        "seed = 1234\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "################################################################################\n",
        "print(\"***** Loading Data ...\")\n",
        "train_data_path = '/content/drive/MyDrive/Colab/0-data/IWSLT2016/'\n",
        "test_data_path = '/content/AMT_LLMs/data/'\n",
        "\n",
        "src_train = open('{}train_{}.txt'.format(train_data_path, src_lang),\n",
        "                 encoding='utf-8').read().strip().split('\\n')\n",
        "trg_train = open('{}train_{}.txt'.format(train_data_path, trg_lang),\n",
        "                 encoding='utf-8').read().strip().split('\\n')\n",
        "src_train = src_preprocess.clean(src_train)\n",
        "trg_train = trg_preprocess.clean(trg_train)\n",
        "src_train_f = []\n",
        "trg_train_f = []\n",
        "for i in range(len(src_train)):\n",
        "    if len(src_train[i].split()) < 20 and len(trg_train[i].split()) < 20:\n",
        "        src_train_f.append(src_train[i])\n",
        "        trg_train_f.append(trg_train[i])\n",
        "\n",
        "src_test = open('{}en_examples.txt'.format(test_data_path),\n",
        "                encoding='utf-8').read().strip().split('\\n')\n",
        "trg_test = open('{}ar_examples.txt'.format(test_data_path),\n",
        "                encoding='utf-8').read().strip().split('\\n')\n",
        "src_test = src_preprocess.clean(src_test)\n",
        "trg_test = trg_preprocess.clean(trg_test)\n",
        "################################################################################\n",
        "print(\"\\n***** Tokenization ...\")\n",
        "src_train = src_preprocess.tokenize(src_train_f)\n",
        "trg_train = trg_preprocess.tokenize(trg_train_f)\n",
        "print(\"\\tTrain Data size\\t\", len(src_train))\n",
        "\n",
        "src_test = src_preprocess.tokenize(src_test)\n",
        "trg_test = trg_preprocess.tokenize(trg_test)\n",
        "################################################################################\n",
        "print(\"\\n***** Creating Vocabulary ...\")\n",
        "\n",
        "src_preprocess.creat_vocabulary(src_train)\n",
        "trg_preprocess.creat_vocabulary(trg_train)\n",
        "\n",
        "print(\"\\t{} Vocabulary size:\\t{}\".format(src_lang, src_preprocess.n_words-4))\n",
        "print(\"\\t{} Vocabulary size:\\t{}\".format(trg_lang, trg_preprocess.n_words-4))\n",
        "################################################################################\n",
        "print(\"\\n***** Creating tensors ...\")\n",
        "src_train_tensor, src_train_mask = src_preprocess.creat_tensors(src_train)\n",
        "trg_train_tensor, trg_train_mask = trg_preprocess.creat_tensors(trg_train)\n",
        "\n",
        "src_test_tensor, src_test_mask = src_preprocess.creat_tensors(src_test)\n",
        "################################################################################\n",
        "print(\"\\n***** Creating Data loaders ...\")\n",
        "dataset = torch.utils.data.TensorDataset(src_train_tensor, src_train_mask,\n",
        "                                         trg_train_tensor, trg_train_mask)\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=128,\n",
        "                                           shuffle=True, num_workers=0)\n",
        "################################################################################\n",
        "print(\"\\n***** Creating Model ...\")\n",
        "INPUT_DIM = src_preprocess.n_words+1\n",
        "OUTPUT_DIM = trg_preprocess.n_words+1\n",
        "positional_encoding = get_positional_encoding(\n",
        "    256, max_length=max(src_train_tensor.shape[1], trg_train_tensor.shape[1]))\n",
        "\n",
        "model = Transformer(INPUT_DIM, OUTPUT_DIM, positional_encoding).to(device)\n",
        "################################################################################\n",
        "print(\"\\n***** Training ...\")\n",
        "train(model, train_loader, device, foldername=foldername)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n***** Testing ...\")\n",
        "model.load_state_dict(torch.load(foldername + 'final_en_ar.pth'))\n",
        "candidates = evaluate(model, trg_test, src_test_tensor.to(device),\n",
        "                      src_test_mask.to(device), trg_preprocess)"
      ],
      "metadata": {
        "id": "gt1QNrpJ6l_T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0f1ff93-8973-4d77-f019-8d6d960559ab"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "***** Testing ...\n",
            "BLEU Score:\t 59.15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertForMaskedLM, BertModel\n",
        "from bert_score import BERTScorer\n",
        "\n",
        "scorer = BERTScorer(model_type='bert-base-uncased', lang='ar')\n",
        "detokenize = MosesDetokenizer(trg_lang)\n",
        "references = [detokenize(sen[1:-1]) for sen in trg_test]\n",
        "_, _, F1 = scorer.score(candidates, references)\n",
        "print(\"BERT Score:\\t\", round(100*F1.mean().item(),2))"
      ],
      "metadata": {
        "id": "eoDH4iuOUVWy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9cbd97c-e3ff-4a7d-b9d9-b9f0141033ae"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT Score:\t 82.95\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DSpvCd40nOWj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "v2EBwTN914p7",
        "PMswNlIi3Vgf",
        "C2IybB0q3ZUd"
      ],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}